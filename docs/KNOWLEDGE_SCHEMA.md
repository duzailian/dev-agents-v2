# AIé©±åŠ¨å›ºä»¶æ™ºèƒ½æµ‹è¯•ç³»ç»Ÿ â€” çŸ¥è¯†åº“æ•°æ®ç»“æ„è®¾è®¡ï¼ˆKNOWLEDGE_SCHEMAï¼‰

> æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0
>
> ç›®æ ‡ï¼šè®¾è®¡å®Œæ•´çš„çŸ¥è¯†åº“æ•°æ®ç»“æ„ï¼ŒåŒ…å«å‘é‡å­˜å‚¨ã€çŸ¥è¯†å•å…ƒæ¨¡å‹ã€äº§å“çº¿æ ‡ç­¾ä½“ç³»ã€æ•°æ®åº“Schemaå’ŒæŸ¥è¯¢ç¤ºä¾‹ã€‚

---

## 1. è®¾è®¡æ¦‚è¿°

### 1.1 çŸ¥è¯†åº“æ¶æ„

çŸ¥è¯†åº“é‡‡ç”¨æ··åˆå­˜å‚¨æ¶æ„ï¼š
- **å‘é‡æ•°æ®åº“ï¼ˆQdrantï¼‰**ï¼šå­˜å‚¨çŸ¥è¯†å•å…ƒçš„è¯­ä¹‰å‘é‡ï¼Œæ”¯æŒç›¸ä¼¼åº¦æ£€ç´¢
- **å…³ç³»æ•°æ®åº“ï¼ˆPostgreSQLï¼‰**ï¼šå­˜å‚¨ç»“æ„åŒ–å…ƒæ•°æ®ï¼Œæ”¯æŒå¤æ‚å…³è”æŸ¥è¯¢
- **æ–‡ä»¶ç³»ç»Ÿ**ï¼šå­˜å‚¨åŸå§‹æ–‡æ¡£ã€ä»£ç ç‰‡æ®µã€æ—¥å¿—æ–‡ä»¶ç­‰å¤§å¯¹è±¡

### 1.2 æ•°æ®æµå‘

```
ä»£ç ä¿®æ”¹ â†’ TestAgent â†’ æ‰§è¡Œç»“æœ â†’ AnalysisAgent â†’ çŸ¥è¯†æå– â†’ 
KnowledgeUnit â†’ å‘é‡åŒ– â†’ Qdrant + PostgreSQL
```

---

## 2. KnowledgeUnit æ•°æ®æ¨¡å‹

### 2.1 æ ¸å¿ƒæ•°æ®ç»“æ„

```json
{
  "id": "ku_20241227_001",
  "content": {
    "title": "PCIeåˆå§‹åŒ–æ—¶åºä¼˜åŒ–",
    "summary": "é’ˆå¯¹Intel Tiger Lakeå¹³å°ï¼ŒPCIeè®¾å¤‡åœ¨å†·å¯åŠ¨åæœªèƒ½æ­£ç¡®æšä¸¾çš„è§£å†³æ–¹æ¡ˆ",
    "description": "è¯¦ç»†æè¿°é—®é¢˜ç°è±¡ã€æ ¹å› åˆ†æã€è§£å†³æ–¹æ¡ˆ...",
    "code_snippets": [
      {
        "file_path": "drivers/pci/pcie.c",
        "function": "pcie_device_init",
        "language": "c",
        "content": "åŸå§‹ä»£ç ç‰‡æ®µæˆ–ä¿®æ”¹åä»£ç "
      }
    ],
    "modification_details": {
      "change_type": "timing_fix",
      "files_modified": ["drivers/pci/pcie.c", "include/pci.h"],
      "lines_added": 15,
      "lines_removed": 8
    }
  },
  "metadata": {
    "product_line": {
      "soc_type": "Tiger_Lake",
      "firmware_stack": "UEFI",
      "chipset": "HM570",
      "platform": "Server"
    },
    "test_context": {
      "test_environment": "QEMU",
      "test_board": "TGL-QEMU",
      "test_duration": "45min",
      "pass_criteria": "pci_devices_detected == 4"
    },
    "execution_result": {
      "status": "success",
      "execution_time": "2024-12-27T10:30:00Z",
      "iterations_count": 3,
      "success_rate": 0.85
    },
    "tags": ["PCIe", "initialization", "enumeration", "timing"],
    "priority": "high",
    "author": "agent_code_v1.2",
    "confidence_score": 0.92
  },
  "relationships": {
    "related_units": ["ku_20241226_015", "ku_20241225_032"],
    "parent_issue": "issue_20241227_001",
    "test_executions": ["te_20241227_001", "te_20241227_002"]
  },
  "vector_embedding": {
    "model": "text-embedding-ada-002",
    "dimension": 1536,
    "vector": [0.1, -0.2, 0.3, ...]
  },
  "audit": {
    "created_at": "2024-12-27T10:35:00Z",
    "updated_at": "2024-12-27T11:20:00Z",
    "version": "1.0",
    "source": "automated_extraction"
  }
}
```

### 2.2 JSON Schema å®šä¹‰

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "KnowledgeUnit",
  "type": "object",
  "required": ["id", "content", "metadata", "vector_embedding", "audit"],
  "properties": {
    "id": {
      "type": "string",
      "pattern": "^ku_[0-9]{8}_[0-9]{3}$",
      "description": "çŸ¥è¯†å•å…ƒå”¯ä¸€æ ‡è¯†ç¬¦ï¼šku_YYYYMMDD_NNN"
    },
    "content": {
      "type": "object",
      "required": ["title", "summary", "description"],
      "properties": {
        "title": {"type": "string", "maxLength": 200},
        "summary": {"type": "string", "maxLength": 500},
        "description": {"type": "string"},
        "code_snippets": {
          "type": "array",
          "items": {
            "type": "object",
            "required": ["file_path", "language", "content"],
            "properties": {
              "file_path": {"type": "string"},
              "function": {"type": "string"},
              "language": {"type": "string", "enum": ["c", "cpp", "assembly", "python", "shell"]},
              "content": {"type": "string"}
            }
          }
        },
        "modification_details": {
          "type": "object",
          "properties": {
            "change_type": {
              "type": "string",
              "enum": ["bug_fix", "feature_add", "performance", "timing_fix", "refactor"]
            },
            "files_modified": {"type": "array", "items": {"type": "string"}},
            "lines_added": {"type": "integer", "minimum": 0},
            "lines_removed": {"type": "integer", "minimum": 0}
          }
        }
      }
    },
    "metadata": {
      "type": "object",
      "required": ["product_line", "test_context", "execution_result", "tags"],
      "properties": {
        "product_line": {
          "type": "object",
          "required": ["soc_type", "firmware_stack"],
          "properties": {
            "soc_type": {"type": "string"},
            "firmware_stack": {"type": "string"},
            "chipset": {"type": "string"},
            "platform": {"type": "string", "enum": ["Server", "Desktop", "Embedded", "Mobile"]}
          }
        },
        "test_context": {
          "type": "object",
          "properties": {
            "test_environment": {"type": "string"},
            "test_board": {"type": "string"},
            "test_duration": {"type": "string"},
            "pass_criteria": {"type": "string"}
          }
        },
        "execution_result": {
          "type": "object",
          "required": ["status", "execution_time"],
          "properties": {
            "status": {"type": "string", "enum": ["success", "failure", "timeout", "error"]},
            "execution_time": {"type": "string", "format": "date-time"},
            "iterations_count": {"type": "integer", "minimum": 1},
            "success_rate": {"type": "number", "minimum": 0, "maximum": 1}
          }
        },
        "tags": {
          "type": "array",
          "items": {"type": "string"},
          "minItems": 1
        },
        "priority": {
          "type": "string",
          "enum": ["low", "medium", "high", "critical"],
          "default": "medium"
        },
        "author": {"type": "string"},
        "confidence_score": {"type": "number", "minimum": 0, "maximum": 1}
      }
    },
    "relationships": {
      "type": "object",
      "properties": {
        "related_units": {
          "type": "array",
          "items": {"type": "string", "pattern": "^ku_[0-9]{8}_[0-9]{3}$"}
        },
        "parent_issue": {"type": "string"},
        "test_executions": {
          "type": "array",
          "items": {"type": "string", "pattern": "^te_[0-9]{8}_[0-9]{3}$"}
        }
      }
    },
    "vector_embedding": {
      "type": "object",
      "required": ["model", "dimension", "vector"],
      "properties": {
        "model": {"type": "string"},
        "dimension": {"type": "integer", "minimum": 1},
        "vector": {
          "type": "array",
          "items": {"type": "number"},
          "minItems": 1
        }
      }
    },
    "audit": {
      "type": "object",
      "required": ["created_at", "version", "source"],
      "properties": {
        "created_at": {"type": "string", "format": "date-time"},
        "updated_at": {"type": "string", "format": "date-time"},
        "version": {"type": "string"},
        "source": {"type": "string", "enum": ["manual", "automated_extraction", "import"]}
      }
    }
  }
}
```

---

## 3. äº§å“çº¿æ ‡ç­¾ä½“ç³»

### 3.1 SoC Type æ ‡ç­¾å®šä¹‰

```yaml
soc_types:
  Intel:
    - "Tiger_Lake"
    - "Alder_Lake" 
    - "Raptor_Lake"
    - "Meteor_Lake"
    - "Arrow_Lake"
    - "Ice_Lake"
    - "Coffee_Lake"
    - "Kaby_Lake"
    - "Broadwell"
    - "Haswell"
    
  AMD:
    - "EPYC_Milan"
    - "EPYC_Genoa"
    - "EPYC_Bergamo"
    - "Ryzen_7000"
    - "Ryzen_5000"
    - "Ryzen_3000"
    
  ARM:
    - "Cortex_A78"
    - "Cortex_A77"
    - "Cortex_A76"
    - "Neoverse_N1"
    - "Neoverse_V1"
    
  Qualcomm:
    - "Snapdragon_8Gen2"
    - "Snapdragon_7Gen1"
    - "Snapdragon_6Gen1"
    
  Other:
    - "Generic_x86_64"
    - "Generic_AArch64"
    - "RISC_V"
```

### 3.2 Firmware Stack æ ‡ç­¾å®šä¹‰

```yaml
firmware_stacks:
  UEFI:
    - "UEFI_2.8"
    - "UEFI_2.9"
    - "UEFI_3.0"
    - "EDK2"
    - "Aptio"
    
  Legacy_BIOS:
    - "Legacy_BIOS"
    - "Coreboot"
    
  BMC_Firmware:
    - "OpenBMC"
    - "IPMI"
    - "Redfish"
    - "AMI_BMC"
    
  Operating_System:
    - "Linux"
    - "FreeRTOS"
    - "Zephyr"
    - "Bare_Metal"
    
  Bootloader:
    - "GRUB"
    - "U-Boot"
    - "SPL"
    - "Bootloader"
```

### 3.3 æ ‡ç­¾ä½“ç³» JSON Schema

```json
{
  "type": "object",
  "properties": {
    "soc_type": {
      "type": "string",
      "enum": [
        "Tiger_Lake", "Alder_Lake", "Raptor_Lake", "Meteor_Lake",
        "EPYC_Milan", "EPYC_Genoa", "Ryzen_7000", "Cortex_A78",
        "Snapdragon_8Gen2", "Generic_x86_64", "Generic_AArch64"
      ]
    },
    "firmware_stack": {
      "type": "string", 
      "enum": [
        "UEFI_2.8", "UEFI_2.9", "UEFI_3.0", "EDK2", "Aptio",
        "Legacy_BIOS", "Coreboot", "OpenBMC", "IPMI", "Redfish",
        "Linux", "FreeRTOS", "Zephyr", "GRUB", "U-Boot"
      ]
    },
    "chipset": {
      "type": "string",
      "examples": ["HM570", "WM590", "TRX40", "X570", "B450"]
    },
    "platform": {
      "type": "string",
      "enum": ["Server", "Desktop", "Embedded", "Mobile"]
    }
  },
  "required": ["soc_type", "firmware_stack"]
}
```

---

## 4. Qdrant å‘é‡æ•°æ®åº“ Schema

### 4.1 Collection é…ç½®

```json
{
  "collection_name": "knowledge_units",
  "vectors": {
    "size": 1536,
    "distance": "Cosine",
    "on_disk_payload": true
  },
  "optimizers_config": {
    "default_segment_number": 2,
    "max_search_threads": 4,
    "indexing_threshold": 20000
  },
  "hnsw_config": {
    "m": 16,
    "ef_construct": 100,
    "full_scan_threshold": 10000
  },
  "wal_config": {
    "wal_capacity_mb": 32,
    "wal_segments_ahead": 4
  }
}
```

### 4.2 Payload Schema å®šä¹‰

```json
{
  "key": "metadata",
  "fields": {
    "product_line": {
      "type": "keyword",
      "fields": {
        "soc_type": {"type": "keyword"},
        "firmware_stack": {"type": "keyword"},
        "chipset": {"type": "keyword"},
        "platform": {"type": "keyword"}
      }
    },
    "test_context": {
      "type": "object",
      "fields": {
        "test_environment": {"type": "keyword"},
        "test_board": {"type": "keyword"},
        "test_duration": {"type": "keyword"}
      }
    },
    "execution_result": {
      "type": "object", 
      "fields": {
        "status": {"type": "keyword"},
        "execution_time": {"type": "datetime"},
        "iterations_count": {"type": "integer"},
        "success_rate": {"type": "float"}
      }
    },
    "tags": {
      "type": "keyword",
      "is_array": true
    },
    "priority": {"type": "keyword"},
    "confidence_score": {"type": "float"}
  }
}
```

### 4.3 åˆ›å»º Collection çš„ Python ä»£ç 

```python
from qdrant_client import QdrantClient
from qdrant_client.http import models

def create_knowledge_units_collection(client: QdrantClient):
    """åˆ›å»ºçŸ¥è¯†å•å…ƒé›†åˆ"""
    
    collection_config = models.CreateCollection(
        collection_name="knowledge_units",
        vectors_config=models.VectorParams(
            size=1536,
            distance=models.Distance.COSINE,
            on_disk_payload=True
        ),
        optimizers_config=models.OptimizersConfig(
            default_segment_number=2,
            max_search_threads=4,
            indexing_threshold=20000
        ),
        hnsw_config=models.HnswConfig(
            m=16,
            ef_construct=100,
            full_scan_threshold=10000
        ),
        wal_config=models.WalConfig(
            wal_capacity_mb=32,
            wal_segments_ahead=4
        ),
        payload_schema={
            "metadata.product_line.soc_type": models.KeywordIndex(),
            "metadata.product_line.firmware_stack": models.KeywordIndex(),
            "metadata.product_line.chipset": models.KeywordIndex(),
            "metadata.product_line.platform": models.KeywordIndex(),
            "metadata.test_context.test_environment": models.KeywordIndex(),
            "metadata.execution_result.status": models.KeywordIndex(),
            "metadata.tags": models.KeywordIndex(),
            "metadata.priority": models.KeywordIndex(),
            "metadata.execution_result.execution_time": models.DatetimeIndex(),
            "metadata.confidence_score": models.FloatIndex()
        }
    )
    
    client.create_collection(collection_config)
    
# ä½¿ç”¨ç¤ºä¾‹
# client = QdrantClient(host="localhost", port=6333)
# create_knowledge_units_collection(client)
```

---

## 5. PostgreSQL å…³ç³»è¡¨ç»“æ„

### 5.1 å»ºè¡¨SQL

```sql
-- çŸ¥è¯†å•å…ƒä¸»è¡¨
CREATE TABLE knowledge_units (
    id VARCHAR(20) PRIMARY KEY,  -- ku_YYYYMMDD_NNN
    title VARCHAR(200) NOT NULL,
    summary TEXT,
    description TEXT NOT NULL,
    change_type VARCHAR(50),
    files_modified TEXT[],
    lines_added INTEGER DEFAULT 0,
    lines_removed INTEGER DEFAULT 0,
    content_vector VECTOR(1536),  -- ä½¿ç”¨ pgvector æ‰©å±•
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    version VARCHAR(10) DEFAULT '1.0',
    source VARCHAR(50) DEFAULT 'automated_extraction',
    author VARCHAR(100),
    confidence_score DECIMAL(3,2),
    metadata JSONB,
    CONSTRAINT ku_id_format CHECK (id ~ '^ku_[0-9]{8}_[0-9]{3}$')
);

-- äº§å“çº¿ä¿¡æ¯è¡¨
CREATE TABLE product_lines (
    id SERIAL PRIMARY KEY,
    soc_type VARCHAR(100) NOT NULL,
    firmware_stack VARCHAR(100) NOT NULL,
    chipset VARCHAR(100),
    platform VARCHAR(50) NOT NULL,
    manufacturer VARCHAR(100),
    launch_year INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(soc_type, firmware_stack, platform)
);

-- ä»£ç ç‰‡æ®µè¡¨
CREATE TABLE code_snippets (
    id SERIAL PRIMARY KEY,
    knowledge_unit_id VARCHAR(20) REFERENCES knowledge_units(id) ON DELETE CASCADE,
    file_path TEXT NOT NULL,
    function_name VARCHAR(200),
    language VARCHAR(50) NOT NULL,
    content TEXT NOT NULL,
    line_start INTEGER,
    line_end INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- æµ‹è¯•æ‰§è¡Œè®°å½•è¡¨
CREATE TABLE test_executions (
    id VARCHAR(20) PRIMARY KEY,  -- te_YYYYMMDD_NNN
    knowledge_unit_id VARCHAR(20) REFERENCES knowledge_units(id),
    test_environment VARCHAR(100) NOT NULL,
    test_board VARCHAR(100),
    test_duration VARCHAR(50),
    pass_criteria TEXT,
    execution_status VARCHAR(20) NOT NULL,
    execution_time TIMESTAMP WITH TIME ZONE,
    iterations_count INTEGER DEFAULT 1,
    success_rate DECIMAL(5,4),
    test_results JSONB,
    artifacts_path TEXT[],
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT te_id_format CHECK (id ~ '^te_[0-9]{8}_[0-9]{3}$'),
    CONSTRAINT valid_status CHECK (execution_status IN ('success', 'failure', 'timeout', 'error'))
);

-- è¿­ä»£è®°å½•è¡¨
CREATE TABLE iteration_records (
    id SERIAL PRIMARY KEY,
    knowledge_unit_id VARCHAR(20) REFERENCES knowledge_units(id) ON DELETE CASCADE,
    iteration_number INTEGER NOT NULL,
    modification_summary TEXT,
    test_result_status VARCHAR(20),
    analysis_conclusion TEXT,
    decision_made VARCHAR(50),
    execution_duration INTERVAL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- æ ‡ç­¾è¡¨
CREATE TABLE tags (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    category VARCHAR(50),  -- domain, component, priority, etc.
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- çŸ¥è¯†å•å…ƒæ ‡ç­¾å…³è”è¡¨
CREATE TABLE knowledge_unit_tags (
    knowledge_unit_id VARCHAR(20) REFERENCES knowledge_units(id) ON DELETE CASCADE,
    tag_id INTEGER REFERENCES tags(id) ON DELETE CASCADE,
    PRIMARY KEY (knowledge_unit_id, tag_id)
);

-- çŸ¥è¯†å•å…ƒå…³è”è¡¨
CREATE TABLE knowledge_unit_relations (
    id SERIAL PRIMARY KEY,
    source_unit_id VARCHAR(20) REFERENCES knowledge_units(id) ON DELETE CASCADE,
    target_unit_id VARCHAR(20) REFERENCES knowledge_units(id) ON DELETE CASCADE,
    relation_type VARCHAR(50) NOT NULL,  -- similar, derived,æ¥è§£å†³, related
    similarity_score DECIMAL(5,4),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT valid_relation_type CHECK (relation_type IN ('similar', 'derived', 'solves', 'related', 'depends_on'))
);

-- å¤–éƒ¨é—®é¢˜è·Ÿè¸ªè¡¨
CREATE TABLE external_issues (
    id VARCHAR(20) PRIMARY KEY,  -- issue_YYYYMMDD_NNN
    knowledge_unit_id VARCHAR(20) REFERENCES knowledge_units(id),
    issue_type VARCHAR(50),  -- bug, feature, enhancement
    priority VARCHAR(20),
    status VARCHAR(20),
    redmine_id INTEGER,  -- Redmineé›†æˆID
    jira_key VARCHAR(50),  # Jiraé›†æˆkey
    title VARCHAR(200),
    description TEXT,
    reported_at TIMESTAMP WITH TIME ZONE,
    resolved_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT issue_id_format CHECK (id ~ '^issue_[0-9]{8}_[0-9]{3}$')
);
```

### 5.2 ç´¢å¼•åˆ›å»º

```sql
-- å‘é‡æœç´¢ç´¢å¼•
CREATE INDEX ON knowledge_units USING ivfflat (content_vector vector_cosine_ops)
    WITH (lists = 100);

-- äº§å“çº¿ç»„åˆç´¢å¼•
CREATE INDEX idx_ku_product_line ON knowledge_units 
    USING GIN ((metadata->'product_line'));

-- æµ‹è¯•çŠ¶æ€ç´¢å¼•
CREATE INDEX idx_test_executions_status ON test_executions (execution_status);
CREATE INDEX idx_test_executions_time ON test_executions (execution_time);

-- æ ‡ç­¾ç´¢å¼•
CREATE INDEX idx_ku_tags ON knowledge_unit_tags (tag_id);
CREATE INDEX idx_tags_category ON tags (category);

-- æ—¶é—´èŒƒå›´ç´¢å¼•
CREATE INDEX idx_ku_created_time ON knowledge_units (created_at);
CREATE INDEX idx_relations_created ON knowledge_unit_relations (created_at);

-- å…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX idx_ku_search ON knowledge_units 
    USING GIN (to_tsvector('english', title || ' ' || description));

-- JSONBå­—æ®µç´¢å¼•
CREATE INDEX idx_ku_metadata ON knowledge_units USING GIN (metadata);
CREATE INDEX idx_test_results ON test_executions USING GIN (test_results);
```

### 5.3 è§†å›¾åˆ›å»º

```sql
-- çŸ¥è¯†å•å…ƒè¯¦ç»†è§†å›¾
CREATE VIEW knowledge_units_detailed AS
SELECT 
    ku.id,
    ku.title,
    ku.summary,
    ku.description,
    ku.change_type,
    ku.files_modified,
    ku.lines_added,
    ku.lines_removed,
    ku.author,
    ku.confidence_score,
    ku.metadata,
    ku.created_at,
    pl.soc_type,
    pl.firmware_stack,
    pl.chipset,
    pl.platform,
    ku.execution_status,
    ku.success_rate,
    array_agg(DISTINCT t.name) as tags
FROM knowledge_units ku
LEFT JOIN product_lines pl ON pl.id = ku.product_line_id
LEFT JOIN knowledge_unit_tags kut ON kut.knowledge_unit_id = ku.id
LEFT JOIN tags t ON t.id = kut.tag_id
GROUP BY ku.id, pl.soc_type, pl.firmware_stack, pl.chipset, pl.platform;

-- æµ‹è¯•æ‰§è¡Œç»Ÿè®¡è§†å›¾
CREATE VIEW test_execution_stats AS
SELECT 
    DATE_TRUNC('day', execution_time) as date,
    test_environment,
    execution_status,
    COUNT(*) as count,
    AVG(iterations_count) as avg_iterations,
    AVG(success_rate) as avg_success_rate
FROM test_executions
WHERE execution_time >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY date, test_environment, execution_status
ORDER BY date DESC, test_environment;

-- æ ‡ç­¾ä½¿ç”¨ç»Ÿè®¡è§†å›¾
CREATE VIEW tag_usage_stats AS
SELECT 
    t.name,
    t.category,
    COUNT(kut.knowledge_unit_id) as usage_count,
    AVG(ku.confidence_score) as avg_confidence
FROM tags t
JOIN knowledge_unit_tags kut ON kut.tag_id = t.id
JOIN knowledge_units ku ON ku.id = kut.knowledge_unit_id
GROUP BY t.id, t.name, t.category
ORDER BY usage_count DESC;
```

---

## 6. æŸ¥è¯¢ç¤ºä¾‹

### 6.1 Qdrant å‘é‡æ£€ç´¢æŸ¥è¯¢

```python
import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.http import models

def semantic_search_knowledge_units(client, query_text, limit=10):
    """åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„çŸ¥è¯†åº“æ£€ç´¢"""
    
    # ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆå®é™…ä½¿ç”¨æ—¶æ¥å…¥embeddingæ¨¡å‹ï¼‰
    query_vector = generate_embedding(query_text)  # [0.1, -0.2, ...]
    
    search_result = client.search(
        collection_name="knowledge_units",
        query_vector=query_vector,
        query_filter=models.Filter(
            must=[
                models.FieldCondition(
                    key="metadata.product_line.soc_type",
                    match=models.MatchValue(value="Tiger_Lake")
                ),
                models.FieldCondition(
                    key="metadata.execution_result.status",
                    match=models.MatchValue(value="success")
                )
            ]
        ),
        limit=limit,
        with_payload=True,
        with_vectors=False
    )
    
    return search_result

def advanced_hybrid_search(client, query_text, filters, limit=20):
    """æ··åˆæ£€ç´¢ï¼šå‘é‡ + å…ƒæ•°æ®è¿‡æ»¤"""
    
    query_vector = generate_embedding(query_text)
    
    # æ„å»ºå¤æ‚çš„è¿‡æ»¤æ¡ä»¶
    must_conditions = []
    
    if filters.get('soc_types'):
        must_conditions.append(
            models.FieldCondition(
                key="metadata.product_line.soc_type",
                match=models.MatchAny(any=filters['soc_types'])
            )
        )
    
    if filters.get('firmware_stacks'):
        must_conditions.append(
            models.FieldCondition(
                key="metadata.product_line.firmware_stack",
                match=models.MatchAny(any=filters['firmware_stacks'])
            )
        )
    
    if filters.get('min_confidence'):
        must_conditions.append(
            models.RangeCondition(
                key="metadata.confidence_score",
                gte=filters['min_confidence']
            )
        )
    
    # æ·»åŠ æ—¥æœŸèŒƒå›´è¿‡æ»¤
    if filters.get('date_from'):
        must_conditions.append(
            models.FieldCondition(
                key="metadata.execution_result.execution_time",
                match=models.MatchDatetime(gt=filters['date_from'])
            )
        )
    
    search_result = client.search(
        collection_name="knowledge_units",
        query_vector=query_vector,
        query_filter=models.Filter(must=must_conditions) if must_conditions else None,
        limit=limit,
        with_payload=True,
        with_vectors=False,
        score_threshold=0.7  # æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
    )
    
    return search_result

# ä½¿ç”¨ç¤ºä¾‹
client = QdrantClient(host="localhost", port=6333)

# 1. åŸºç¡€è¯­ä¹‰æœç´¢
results = semantic_search_knowledge_units(
    client, 
    "PCIe device enumeration timing issues",
    limit=5
)

# 2. é«˜çº§æ··åˆæœç´¢
advanced_results = advanced_hybrid_search(
    client,
    "UEFI initialization problems",
    {
        'soc_types': ['Tiger_Lake', 'Alder_Lake'],
        'firmware_stacks': ['UEFI_2.8', 'UEFI_2.9'],
        'min_confidence': 0.8,
        'date_from': '2024-01-01T00:00:00Z'
    },
    limit=10
)
```

### 6.2 PostgreSQL å¤æ‚æŸ¥è¯¢ç¤ºä¾‹

```sql
-- 1. æŸ¥æ‰¾ç‰¹å®šäº§å“çº¿çš„é«˜ç½®ä¿¡åº¦è§£å†³æ–¹æ¡ˆ
SELECT 
    ku.id,
    ku.title,
    ku.summary,
    ku.confidence_score,
    ku.created_at,
    pl.soc_type,
    pl.firmware_stack,
    array_agg(DISTINCT t.name) as relevant_tags
FROM knowledge_units ku
JOIN product_lines pl ON (
    ku.metadata->'product_line'->>'soc_type' = pl.soc_type 
    AND ku.metadata->'product_line'->>'firmware_stack' = pl.firmware_stack
)
LEFT JOIN knowledge_unit_tags kut ON kut.knowledge_unit_id = ku.id
LEFT JOIN tags t ON t.id = kut.tag_id
WHERE pl.soc_type = 'Tiger_Lake'
  AND pl.firmware_stack = 'UEFI_2.8'
  AND ku.confidence_score >= 0.85
  AND ku.metadata->'execution_result'->>'status' = 'success'
GROUP BY ku.id, ku.title, ku.summary, ku.confidence_score, ku.created_at, pl.soc_type, pl.firmware_stack
ORDER BY ku.confidence_score DESC, ku.created_at DESC
LIMIT 10;

-- 2. åˆ†ææµ‹è¯•æ‰§è¡Œè¶‹åŠ¿
WITH test_trends AS (
    SELECT 
        DATE_TRUNC('week', te.execution_time) as week,
        te.test_environment,
        COUNT(*) as total_executions,
        COUNT(*) FILTER (WHERE te.execution_status = 'success') as successful_executions,
        ROUND(
            COUNT(*) FILTER (WHERE te.execution_status = 'success') * 100.0 / COUNT(*), 2
        ) as success_rate_percent
    FROM test_executions te
    WHERE te.execution_time >= CURRENT_DATE - INTERVAL '12 weeks'
      AND te.knowledge_unit_id IS NOT NULL
    GROUP BY week, te.test_environment
)
SELECT 
    week,
    test_environment,
    total_executions,
    successful_executions,
    success_rate_percent,
    LAG(success_rate_percent) OVER (PARTITION BY test_environment ORDER BY week) as prev_week_success_rate,
    success_rate_percent - LAG(success_rate_percent) OVER (PARTITION BY test_environment ORDER BY week) as success_rate_change
FROM test_trends
ORDER BY week DESC, test_environment;

-- 3. æŸ¥æ‰¾ç›¸å…³çŸ¥è¯†å•å…ƒ
WITH similar_units AS (
    SELECT DISTINCT
        ku1.id as source_unit,
        ku2.id as target_unit,
        ku2.title,
        ku2.summary,
        ku2.confidence_score,
        -- åŸºäºæ ‡ç­¾é‡å è®¡ç®—ç›¸ä¼¼åº¦
        (
            SELECT COUNT(*) * 1.0 / 
                   GREATEST(
                       (SELECT COUNT(*) FROM knowledge_unit_tags WHERE knowledge_unit_id = ku1.id),
                       (SELECT COUNT(*) FROM knowledge_unit_tags WHERE knowledge_unit_id = ku2.id)
                   )
            FROM knowledge_unit_tags kut1
            JOIN knowledge_unit_tags kut2 ON kut1.tag_id = kut2.tag_id
            WHERE kut1.knowledge_unit_id = ku1.id 
              AND kut2.knowledge_unit_id = ku2.id
        ) as tag_similarity
    FROM knowledge_units ku1
    JOIN knowledge_unit_tags kut1 ON kut1.knowledge_unit_id = ku1.id
    JOIN knowledge_unit_tags kut2 ON kut2.tag_id = kut1.tag_id
    JOIN knowledge_units ku2 ON ku2.id = kut2.knowledge_unit_id
    WHERE ku1.id = 'ku_20241227_001'
      AND ku2.id != 'ku_20241227_001'
      AND ku2.metadata->'execution_result'->>'status' = 'success'
)
SELECT 
    target_unit,
    title,
    summary,
    confidence_score,
    tag_similarity,
    ROUND(tag_similarity * 100, 2) as similarity_percent
FROM similar_units
WHERE tag_similarity >= 0.3
ORDER BY tag_similarity DESC, confidence_score DESC
LIMIT 5;

-- 4. äº§å“çº¿é—®é¢˜åˆ†å¸ƒåˆ†æ
SELECT 
    pl.soc_type,
    pl.firmware_stack,
    COUNT(ku.id) as total_issues,
    COUNT(ku.id) FILTER (WHERE ku.metadata->'execution_result'->>'status' = 'success') as resolved_issues,
    COUNT(ku.id) FILTER (WHERE ku.metadata->'execution_result'->>'status' = 'failure') as unresolved_issues,
    ROUND(
        COUNT(ku.id) FILTER (WHERE ku.metadata->'execution_result'->>'status' = 'success') * 100.0 / 
        NULLIF(COUNT(ku.id), 0), 2
    ) as resolution_rate_percent,
    AVG(ku.confidence_score) as avg_confidence
FROM product_lines pl
LEFT JOIN knowledge_units ku ON (
    ku.metadata->'product_line'->>'soc_type' = pl.soc_type 
    AND ku.metadata->'product_line'->>'firmware_stack' = pl.firmware_stack
)
GROUP BY pl.id, pl.soc_type, pl.firmware_stack
HAVING COUNT(ku.id) > 0
ORDER BY resolution_rate_percent DESC, total_issues DESC;

-- 5. ä»£ç ä¿®æ”¹æ¨¡å¼åˆ†æ
SELECT 
    change_type,
    COUNT(*) as change_count,
    AVG(lines_added) as avg_lines_added,
    AVG(lines_removed) as avg_lines_removed,
    AVG(confidence_score) as avg_confidence,
    array_agg(DISTINCT soc_type) as affected_soc_types
FROM (
    SELECT 
        ku.change_type,
        ku.lines_added,
        ku.lines_removed,
        ku.confidence_score,
        ku.metadata->'product_line'->>'soc_type' as soc_type
    FROM knowledge_units ku
    WHERE ku.change_type IS NOT NULL
      AND ku.created_at >= CURRENT_DATE - INTERVAL '3 months'
) subquery
GROUP BY change_type
ORDER BY change_count DESC;

-- 6. æœ€è¿‘æ´»è·ƒçš„çŸ¥è¯†å•å…ƒ
SELECT 
    ku.id,
    ku.title,
    ku.summary,
    ku.confidence_score,
    ku.created_at,
    ku.updated_at,
    ku.metadata->'product_line'->>'soc_type' as soc_type,
    ku.metadata->'execution_result'->>'status' as status,
    -- æ£€æŸ¥æ˜¯å¦æœ‰æœ€è¿‘çš„å…³è”æµ‹è¯•
    CASE 
        WHEN EXISTS (
            SELECT 1 FROM test_executions te 
            WHERE te.knowledge_unit_id = ku.id 
            AND te.created_at >= CURRENT_DATE - INTERVAL '7 days'
        ) THEN 'recently_tested'
        ELSE 'no_recent_test'
    END as test_status
FROM knowledge_units ku
WHERE ku.created_at >= CURRENT_DATE - INTERVAL '30 days'
  AND ku.metadata->'execution_result'->>'status' = 'success'
ORDER BY ku.updated_at DESC, ku.confidence_score DESC
LIMIT 15;
```

### 6.3 ç»„åˆæŸ¥è¯¢ï¼šå‘é‡æ£€ç´¢ + å…³ç³»æ•°æ®

```python
import psycopg2
from qdrant_client import QdrantClient

def comprehensive_search(query_text, soc_type=None, min_confidence=0.7, limit=10):
    """ç»¼åˆæ£€ç´¢ï¼šå…ˆå‘é‡æœç´¢ï¼Œå†å…³ç³»æ•°æ®è¿‡æ»¤å’Œè¡¥å……"""
    
    qdrant_client = QdrantClient(host="localhost", port=6333)
    
    # æ­¥éª¤1ï¼šå‘é‡æ£€ç´¢å€™é€‰ç»“æœ
    vector_results = qdrant_client.search(
        collection_name="knowledge_units",
        query_vector=generate_embedding(query_text),
        limit=limit * 2,  # è·å–æ›´å¤šå€™é€‰ç»“æœè¿›è¡Œåç»­è¿‡æ»¤
        with_payload=True
    )
    
    if not vector_results:
        return []
    
    # æ­¥éª¤2ï¼šæå–å€™é€‰IDs
    candidate_ids = [r.id for r in vector_results]
    
    # æ­¥éª¤3ï¼šPostgreSQLå…³ç³»æ•°æ®è¡¥å……
    conn = psycopg2.connect(
        host="localhost",
        database="knowledge_db", 
        user="kb_user",
        password="kb_password"
    )
    
    with conn.cursor() as cur:
        # è·å–å®Œæ•´ä¿¡æ¯
        query = """
        SELECT 
            ku.id,
            ku.title,
            ku.summary,
            ku.description,
            ku.confidence_score,
            ku.metadata,
            ku.created_at,
            pl.soc_type,
            pl.firmware_stack,
            ku.metadata->'execution_result'->>'status' as status,
            array_agg(DISTINCT t.name) as tags
        FROM knowledge_units ku
        LEFT JOIN product_lines pl ON (
            ku.metadata->'product_line'->>'soc_type' = pl.soc_type 
            AND ku.metadata->'product_line'->>'firmware_stack' = pl.firmware_stack
        )
        LEFT JOIN knowledge_unit_tags kut ON kut.knowledge_unit_id = ku.id
        LEFT JOIN tags t ON t.id = kut.tag_id
        WHERE ku.id = ANY(%s)
        """
        
        params = [candidate_ids]
        
        if soc_type:
            query += " AND pl.soc_type = %s"
            params.append(soc_type)
        
        if min_confidence:
            query += " AND ku.confidence_score >= %s"
            params.append(min_confidence)
        
        query += """
        GROUP BY ku.id, ku.title, ku.summary, ku.description, 
                 ku.confidence_score, ku.metadata, ku.created_at, 
                 pl.soc_type, pl.firmware_stack
        ORDER BY ku.confidence_score DESC, ku.created_at DESC
        LIMIT %s
        """
        params.append(limit)
        
        cur.execute(query, params)
        results = cur.fetchall()
    
    conn.close()
    
    # æ­¥éª¤4ï¼šç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³ç³»æ•°æ®ç½®ä¿¡åº¦è¿›è¡Œæœ€ç»ˆæ’åº
    enhanced_results = []
    for result in results:
        ku_id = result[0]
        
        # æ‰¾åˆ°å¯¹åº”çš„å‘é‡æ£€ç´¢ç»“æœ
        vector_result = next((r for r in vector_results if r.id == ku_id), None)
        if vector_result:
            enhanced_results.append({
                'id': ku_id,
                'title': result[1],
                'summary': result[2],
                'description': result[3],
                'confidence_score': result[4],
                'metadata': result[5],
                'created_at': result[6],
                'soc_type': result[7],
                'firmware_stack': result[8],
                'status': result[9],
                'tags': result[10] or [],
                'vector_similarity': vector_result.score,  # å‘é‡ç›¸ä¼¼åº¦
                'combined_score': (result[4] + vector_result.score) / 2  # ç»„åˆå¾—åˆ†
            })
    
    # æŒ‰ç»„åˆå¾—åˆ†é‡æ–°æ’åº
    enhanced_results.sort(key=lambda x: x['combined_score'], reverse=True)
    
    return enhanced_results[:limit]

# ä½¿ç”¨ç¤ºä¾‹
results = comprehensive_search(
    query_text="PCIe initialization and device enumeration",
    soc_type="Tiger_Lake", 
    min_confidence=0.8,
    limit=5
)

for result in results:
    print(f"ID: {result['id']}")
    print(f"Title: {result['title']}")
    print(f"Confidence: {result['confidence_score']:.2f}")
    print(f"Vector Similarity: {result['vector_similarity']:.3f}")
    print(f"Combined Score: {result['combined_score']:.3f}")
    print(f"Tags: {', '.join(result['tags'])}")
    print("-" * 50)
```

---

## 7. æ•°æ®è¿ç§»å’Œç»´æŠ¤

### 7.1 æ•°æ®å¯¼å…¥è„šæœ¬

```python
import json
import uuid
from datetime import datetime
from qdrant_client import QdrantClient
import psycopg2

def import_knowledge_units_from_json(file_path):
    """ä»JSONæ–‡ä»¶æ‰¹é‡å¯¼å…¥çŸ¥è¯†å•å…ƒ"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    qdrant_client = QdrantClient(host="localhost", port=6333)
    
    # PostgreSQLè¿æ¥
    pg_conn = psycopg2.connect(
        host="localhost",
        database="knowledge_db",
        user="kb_user", 
        password="kb_password"
    )
    
    try:
        for item in data:
            ku_id = item['id']
            
            # 1. æ’å…¥PostgreSQL
            insert_postgresql_knowledge_unit(pg_conn, item)
            
            # 2. æ’å…¥Qdrant
            insert_qdrant_knowledge_unit(qdrant_client, item)
            
            print(f"âœ… å¯¼å…¥çŸ¥è¯†å•å…ƒ: {ku_id}")
            
        pg_conn.commit()
        print(f"ğŸ‰ æˆåŠŸå¯¼å…¥ {len(data)} ä¸ªçŸ¥è¯†å•å…ƒ")
        
    except Exception as e:
        pg_conn.rollback()
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        raise
    finally:
        pg_conn.close()

def insert_postgresql_knowledge_unit(conn, ku_data):
    """æ’å…¥å•ä¸ªçŸ¥è¯†å•å…ƒåˆ°PostgreSQL"""
    with conn.cursor() as cur:
        # æ’å…¥knowledge_unitsè¡¨
        cur.execute("""
            INSERT INTO knowledge_units (
                id, title, summary, description, change_type, files_modified,
                lines_added, lines_removed, author, confidence_score,
                metadata, created_at, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (id) DO UPDATE SET
                title = EXCLUDED.title,
                summary = EXCLUDED.summary, 
                description = EXCLUDED.description,
                metadata = EXCLUDED.metadata,
                updated_at = EXCLUDED.updated_at
        """, (
            ku_data['id'],
            ku_data['content']['title'],
            ku_data['content']['summary'],
            ku_data['content']['description'],
            ku_data['content']['modification_details']['change_type'],
            ku_data['content']['modification_details']['files_modified'],
            ku_data['content']['modification_details']['lines_added'],
            ku_data['content']['modification_details']['lines_removed'],
            ku_data['metadata']['author'],
            ku_data['metadata']['confidence_score'],
            json.dumps(ku_data['metadata']),
            ku_data['audit']['created_at'],
            ku_data['audit']['updated_at']
        ))
        
        # æ’å…¥ä»£ç ç‰‡æ®µ
        for snippet in ku_data['content']['code_snippets']:
            cur.execute("""
                INSERT INTO code_snippets (
                    knowledge_unit_id, file_path, function_name, language, content
                ) VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT DO NOTHING
            """, (
                ku_data['id'],
                snippet['file_path'],
                snippet.get('function'),
                snippet['language'],
                snippet['content']
            ))

def insert_qdrant_knowledge_unit(client, ku_data):
    """æ’å…¥å•ä¸ªçŸ¥è¯†å•å…ƒåˆ°Qdrant"""
    
    client.upsert(
        collection_name="knowledge_units",
        points=[models.PointStruct(
            id=ku_data['id'],
            vector=ku_data['vector_embedding']['vector'],
            payload={
                'metadata': ku_data['metadata'],
                'title': ku_data['content']['title'],
                'summary': ku_data['content']['summary']
            }
        )]
    )

# æ‰§è¡Œå¯¼å…¥
# import_knowledge_units_from_json('/data/knowledge_units_export.json')
```

### 7.2 æ•°æ®ç»´æŠ¤è„šæœ¬

```python
def cleanup_orphaned_data():
    """æ¸…ç†å­¤ç«‹çš„æµ‹è¯•æ‰§è¡Œè®°å½•å’Œå…³è”æ•°æ®"""
    
    conn = psycopg2.connect(
        host="localhost",
        database="knowledge_db",
        user="kb_user",
        password="kb_password"
    )
    
    try:
        with conn.cursor() as cur:
            # åˆ é™¤æ²¡æœ‰çŸ¥è¯†å•å…ƒå…³è”çš„æµ‹è¯•æ‰§è¡Œè®°å½•
            cur.execute("""
                DELETE FROM test_executions 
                WHERE knowledge_unit_id IS NOT NULL 
                AND knowledge_unit_id NOT IN (SELECT id FROM knowledge_units)
            """)
            
            # åˆ é™¤æ²¡æœ‰çŸ¥è¯†å•å…ƒå…³è”çš„æ ‡ç­¾å…³è”
            cur.execute("""
                DELETE FROM knowledge_unit_tags 
                WHERE knowledge_unit_id NOT IN (SELECT id FROM knowledge_units)
            """)
            
            # åˆ é™¤æ²¡æœ‰çŸ¥è¯†å•å…ƒå…³è”çš„è¿­ä»£è®°å½•
            cur.execute("""
                DELETE FROM iteration_records 
                WHERE knowledge_unit_id NOT IN (SELECT id FROM knowledge_units)
            """)
            
            deleted_count = cur.rowcount
            print(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} æ¡å­¤ç«‹è®°å½•")
            
        conn.commit()
        
    finally:
        conn.close()

def update_confidence_scores():
    """æ›´æ–°çŸ¥è¯†å•å…ƒçš„ç½®ä¿¡åº¦åˆ†æ•°"""
    
    conn = psycopg2.connect(
        host="localhost", 
        database="knowledge_db",
        user="kb_user",
        password="kb_password"
    )
    
    try:
        with conn.cursor() as cur:
            # åŸºäºæ‰§è¡Œç»“æœæ›´æ–°ç½®ä¿¡åº¦
            cur.execute("""
                UPDATE knowledge_units 
                SET confidence_score = 
                    CASE 
                        WHEN metadata->'execution_result'->>'status' = 'success' THEN 
                            LEAST(0.95, confidence_score + 0.1)
                        WHEN metadata->'execution_result'->>'status' = 'failure' THEN
                            GREATEST(0.1, confidence_score - 0.1)
                        ELSE confidence_score
                    END
                WHERE metadata->'execution_result'->>'status' IS NOT NULL
            """)
            
            updated_count = cur.rowcount
            print(f"ğŸ“Š æ›´æ–°äº† {updated_count} ä¸ªç½®ä¿¡åº¦åˆ†æ•°")
            
        conn.commit()
        
    finally:
        conn.close()

def generate_usage_report():
    """ç”ŸæˆçŸ¥è¯†åº“ä½¿ç”¨æŠ¥å‘Š"""
    
    conn = psycopg2.connect(
        host="localhost",
        database="knowledge_db", 
        user="kb_user",
        password="kb_password"
    )
    
    try:
        with conn.cursor() as cur:
            # æ•´ä½“ç»Ÿè®¡
            cur.execute("SELECT COUNT(*) FROM knowledge_units")
            total_units = cur.fetchone()[0]
            
            cur.execute("SELECT COUNT(*) FROM knowledge_units WHERE confidence_score >= 0.8")
            high_confidence = cur.fetchone()[0]
            
            cur.execute("SELECT COUNT(*) FROM test_executions WHERE execution_status = 'success'")
            successful_tests = cur.fetchone()[0]
            
            print("ğŸ“ˆ çŸ¥è¯†åº“ä½¿ç”¨æŠ¥å‘Š")
            print("=" * 40)
            print(f"æ€»çŸ¥è¯†å•å…ƒæ•°: {total_units}")
            print(f"é«˜ç½®ä¿¡åº¦å•å…ƒ: {high_confidence} ({high_confidence/total_units*100:.1f}%)")
            print(f"æˆåŠŸæµ‹è¯•æ•°: {successful_tests}")
            
            # æŒ‰äº§å“çº¿ç»Ÿè®¡
            cur.execute("""
                SELECT 
                    metadata->'product_line'->>'soc_type' as soc_type,
                    COUNT(*) as count,
                    AVG(confidence_score) as avg_confidence
                FROM knowledge_units
                GROUP BY metadata->'product_line'->>'soc_type'
                ORDER BY count DESC
            """)
            
            print("\nğŸ”§ æŒ‰SoCç±»å‹ç»Ÿè®¡:")
            for row in cur.fetchall():
                print(f"  {row[0]}: {row[1]} å•å…ƒ, å¹³å‡ç½®ä¿¡åº¦: {row[2]:.2f}")
                
    finally:
        conn.close()

# æ‰§è¡Œç»´æŠ¤ä»»åŠ¡
if __name__ == "__main__":
    print("å¼€å§‹æ•°æ®ç»´æŠ¤...")
    cleanup_orphaned_data()
    update_confidence_scores()
    generate_usage_report()
    print("æ•°æ®ç»´æŠ¤å®Œæˆ!")
```

---

## 8. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 8.1 Qdrant æ€§èƒ½ä¼˜åŒ–

```python
# ä¼˜åŒ–é…ç½®
OPTIMIZATION_CONFIG = {
    # ç´¢å¼•ä¼˜åŒ–
    "indexing_threshold": 20000,  # è‡ªåŠ¨ç´¢å¼•çš„æ¡ç›®é˜ˆå€¼
    "max_optimization_threads": 4,
    
    # å†…å­˜ä¼˜åŒ–  
    "memmap_threshold_kb": 100,  # å†…å­˜æ˜ å°„é˜ˆå€¼
    "max_search_threads": 4,     # å¹¶è¡Œæœç´¢çº¿ç¨‹æ•°
    
    # HNSWå‚æ•°ä¼˜åŒ–
    "hnsw_m": 16,                # è¿æ¥æ•°ï¼Œå½±å“æœç´¢ç²¾åº¦å’Œå†…å­˜
    "hnsw_ef_construct": 100,    # æ„å»ºæ—¶çš„æœç´¢èŒƒå›´
    "hnsw_full_scan_threshold": 10000,  # å…¨è¡¨æ‰«æé˜ˆå€¼
}

# ç›‘æ§æŸ¥è¯¢æ€§èƒ½
def monitor_qdrant_performance(client):
    """ç›‘æ§Qdrantæ€§èƒ½æŒ‡æ ‡"""
    
    collection_info = client.get_collection("knowledge_units")
    
    print("ğŸ“Š Qdrant æ€§èƒ½æŒ‡æ ‡")
    print("=" * 30)
    print(f"å‘é‡æ•°é‡: {collection_info.vectors_count}")
    print(f"ç´¢å¼•çŠ¶æ€: {collection_info.indexed_vectors_count}")
    print(f"æ®µæ•°é‡: {collection_info.segments_count}")
    print(f"çŠ¶æ€: {collection_info.status}")
```

### 8.2 PostgreSQL æ€§èƒ½ä¼˜åŒ–

```sql
-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æœˆåˆ†åŒºï¼‰
CREATE TABLE knowledge_units_partitioned (
    LIKE knowledge_units INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE knowledge_units_2024_12 PARTITION OF knowledge_units_partitioned
    FOR VALUES FROM ('2024-12-01') TO ('2025-01-01');

-- æŸ¥è¯¢ä¼˜åŒ–é…ç½®
ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET work_mem = '4MB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';

-- å¯ç”¨å¹¶è¡ŒæŸ¥è¯¢
ALTER SYSTEM SET max_parallel_workers = 4;
ALTER SYSTEM SET max_parallel_workers_per_gather = 2;
```

---

æœ¬æ–‡æ¡£æä¾›äº†å®Œæ•´çš„çŸ¥è¯†åº“æ•°æ®ç»“æ„è®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…å«300+è¡Œè¯¦ç»†è§„èŒƒï¼Œæ¶µç›–äº†æ•°æ®æ¨¡å‹ã€å­˜å‚¨æ¶æ„ã€æŸ¥è¯¢ç¤ºä¾‹å’Œæ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€‚è®¾è®¡æ”¯æŒé«˜æ•ˆçš„è¯­ä¹‰æ£€ç´¢ã€ç»“æ„åŒ–æ•°æ®ç®¡ç†å’Œäº§å“çº¿å·®å¼‚åŒ–æŸ¥è¯¢ï¼Œä¸ºAIé©±åŠ¨çš„å›ºä»¶æµ‹è¯•ç³»ç»Ÿæä¾›äº†åšå®çš„æ•°æ®åŸºç¡€ã€‚